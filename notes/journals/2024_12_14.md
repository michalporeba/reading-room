- Listening to [[Code Dependent]]
	- Chapter 4 - Your Health
		- Use of AI in medicine, on example of augmenting trained physicians in remote areas were the second human opinion is not possible. The example here is an Indian [[Qure.ai]] and its use in remote areas of India in late [[2010s]]
		- The conclusion is, that although the AI could benefit remote and disadvantaged population's health, they are subject to [[Data Colonialism]]. They are used to harvest the data and to build tools which are then sold at a premium in more affluent areas of the world. To some extent the modern healthcare is possible thanks to practices which we would consider incompatible with our own sense of privacy and data ownership.
	- Chapter 5 - Year Freedom
		- The chapter focuses on the example of Amsterdam's top 600 and top 400 lists where AI was used to predict likely hood of children's offending in the attempt to prevent them from offending in the future.
		- There were many problems with this approach, among them, the fact that the data on which the algorithm was trained was about arrests not offences committed and so minorities and immigrant communities were targeted by the predictions as they were by humans for the arrests.
		- One of the lessons learned was that what worked better is remembering that the potential future offender is a person and might need a human centered support rather than be treated mechanically based on a statistical model's prediction.
		- Still, the AI based policing appears to be here to stay with all its biases.