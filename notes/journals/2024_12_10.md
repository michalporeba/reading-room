- Reading [[Kafka: The Definitive Guide]]
	- Details on setup of Kafka clusters, administration and monitoring.
	- Useful details on how replication affects throughput - it is a trade off
	- Chapter 11 - Stream Processing
		- [[Quote]]: "a data stream is an abstraction representing an unbounded dataset. Unbounded means infinite and ever growing. The dataset is unbounded because over time, new records keep arriving. This definition is used by [Google](https://www.oreilly.com/radar/the-world-beyond-batch-streaming-101/), [Amazon](https://aws.amazon.com/what-is/streaming-data/), and pretty much everyone else.
		  id:: 67589ec8-81cc-433e-a6d2-6b7c8df3de1d
	- The event streams model has additional properties to their unbounded nature
		- event streams are ordered
		- they are immutable data records
		- even stream are replayable
	- From the software architecture perspective we have to consider the following types of data processing
		- request-response - the lowest latency paradigm. It is the same as [[OLTP]] in the database world.
		- batch processing - high latency / high throughput option. This is the [[Enterprise Data Warehouse]] approach
		- stream processing  - a continuous and non - blocking option. It fits between request-response and batch processing.
	- Reference to time and [[There is No Now]] paper.
	- Lists patterns of stream processing design pattern - a useful reference, including:
		- Single-Event Processing
		- Processing with Local State
		- Multiphase Processing / Repartitioning
		- Processing with External Lookup: Stream-Table Join
		- Stream Joining
		- Out of Sequence Events
		- Reprocessing
		-
-