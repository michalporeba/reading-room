- Listening to [[Code Dependent]]
	- Chapter 7 - Your Boss
		- The chapter starts with the story of [[Armin Samii]] who through his career kept improving things by complaining to his bosses about the things that weren't right. He tried working for [[Uber]] as a delivery biker, but quit after just 3 weeks and 21 trip. "Working for an illogical system and a boss he couldn't complain to, was antithetical to his character".
		- He built the [[Uber Cheats]] app that has shown that intentionally or not, the algorithms employed by [[Uber]] to pay for the deliveries were skewed in favour of the organisation.
		- [[Quote]]: When you see who is getting hurt the most, he said, it is already people who are getting hurt by existing systems but it exacerbates these differences. Uber Cheats was a window into the innards of gig work algorithms that app workers are firmly locked out of. The apparent miscalculation of distances suggested something the app workers have always suspected. Algorithms have blind spot for human factors like unexpected delays or route extensions by gnarly traffic jams, weather events, roadworks or crowded restaurants that keep workers waiting.
		- Workers data is used to optimise the large business, but they don't have access to it, so they don't know how their behaviour affects their pay. They have no opportunity to optimise the behaviour and the pay.
		- [[Quote]]: The structure that is holey dependent on human labour yet treats its workers as automatons.
		- There is a growing class of people who work like that, whose incomes are unpredictable, whose pay is dependent on algorithms they don't understand.
		- A link is made to [Kafka]([[Franz Kafka]])'s [[Trial]] where humans are judged and their lives are affected, but there is no way to know why. This is shown on an example of [[Uber]] driver from [[London]], [[Alexandru Iftimie]] who's behaviour was incorrectly marked as frodulent by Uber. He's story is also described by [[The Guardian]] in [[Stop or I'll fire you: the driver who defied Uber's automated HR]] article.
		- Code dependent - we shape algorithms and the algorithms shape us, our behaviour.
	- Chapter 8 - Your Rights
		- [[Cori Crider]] a lawyer and an activist from [[Texas]] but living in [[London]] makes comparison between [[Guantanamo Bay]] detainees and content moderators at [[Facebook]], [[Instagram]], [[TikTok]]. She interviewed over 100 moderators, including [[Daniel Motaung]] from the famous case [[Motaung v Meta]]. He was employed in [[Kenya]] by [[Sama]] the same outsourcing company as mentioned in the first chapter in the story from [[Nairobi]].
		- The issues is also described in [[The Guardian]] in their [[Taking on the tech giants: the lawyer fighting the power of algorithmic systems]] article.
		- [[Cori Crider]] founded [[Foxglove]]
		- [[Foxglove]] took [[Home Office]] to court for automated racial profiling of visa applicants.
		- The narrative moves to the story of [[Faisal bin Ali Jaber]]. Two of his family members were killed in an American [[Signature Strike]] in [[Khashamir]], [[Yemen]]. The strike happened in [[2012]] and happened when his family members inadvertently met with three suspected individuals. The whole group was identified and targeted not as individual, but based on behaviour pattern analysis.
		- It is another example, where human lives (and deaths) are affected by the AI and data analysis.