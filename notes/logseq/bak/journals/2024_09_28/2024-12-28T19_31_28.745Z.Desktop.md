- Listening to [[Supremacy]]
	- More details of the early stories of how OpenAI and DeepMind came to be. There are many names of famous Silicon Valley entrepreneurs mentioned but one comes up more often then the others - [[Elon Musk]]. He had a lot of interest in the field and the ambitions, and the ego to match the two main characters of the story.
	- Both [[Sam Altman]] and [[Demis Hassabis]] fought to stay close to their benevolent ideas and visions for the AI that will solve the humanity problems. Hassabies often prophesying that the economy as we know it will end soon, perhaps in five years, and the financial concerns of individuals will be those of the past. But the commercial reality was that their research and advances in the field required substantial reserves of cash. Such cash was only available at the biggest of "tech" companies. Their business centred around advertisement could benefit greatly from the advances in artificial intelligence.
	- The book does a good job of explaining the forces that led the initial ideas of solving world problem, of doing things in the open for the good of humanity, to solutions that are mostly private and drive revenue for a few, and automated discrimination for the many.
	- There were number of issues and early problems showcased. They were all swept under the carpet as in the example when Google's AI classified black people as "gorillas". The problem was solved by removing the label "gorilla" from the training data. Solving such problems was not important as the commercial focus has been on creating hyper addictive platforms for advertising - especially for the Google / Alphabet, and Facebook / Meta.
	- The ethics discussion moves to [[Timnit Gebru]], an Eritrean Ethiopian-born computer scientist with an experience of racial profiling and discrimination. She was an early and a very strong voice against racism and other biases in the models being built. One of the examples given was that of using AI for " proactive policing" in the US that lead to targeting minorities.
	- The discussion about ethics and safeguards for AI is compared to plastic recycling campaigns. While in principal well intended, the campaigns shifted the discourse from the responsibility of the producers of the plastics, to the consumers. In the similar was talking about AI safety in the context of autonomous robots taking over the universe means that the more immediate, and perhaps more real issues of the technology are not discussed, the problems are to be solved by the users, not the creators.
	- In a few places in the book, especially when talking about concerns, or the lack of concerns with the technology the concept of [[Transhumanism]] is mentioned and linked to earlier [[Eugenics]], and elitist ideology that, among other things led to, or was abused by the Nazis.
	- Chapter 9 - the Goliath Paradox. Google has grown too big to really innovate, as any changes to what they did where commercially too risky. So, despite the fact that the researchers at Google come up with the transformers, and noticed that when such systems where used for text translation "core reference resolution" became possible, they couldn't apply their invention. They made the research publicly available
	- LATER [[Attention is all you need]] a paper by eight google scientists that revolutionised machine learning field. The paper has been cited over 100,000 times by 2024 in just 7 years
	- All eight authors left google not long after the publication because they were not able to apply the technology. It was inadvertently left to other companies, including OpenAI
- Listening to [[Learn French with Paul Noble for Beginners - Complete Course]]
	- Mostly exercises, but in-between the there are very useful bits of information oh how to use the knowledge of English to learn to speak French.
- Read again Виктор Суворов - [[Аквариум]]. Perhaps this time in the original? It's been probably close to 20 years when I read it for the first time.